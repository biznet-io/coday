# Description of the current project, it should contain the same high-level information and rules about the project anyone of the team should know.
#
# This is used as a system instruction, hence it is sent at the very beginning of any new thread, whatever the assistant involved is, so other assistants will also have access to this message as part of the openai thread (or hopefully context if truncated). If using the default Coday assistant (that is kept quite generic and close to default LLM), the more detailed and broad the description, the more Coday's responses are relevant (by a very wide margin).
#
# Recommendations: write it in markdown as you would write human-intended documentation
description: |
  ## Project description
  
  Coday is a lightweight framework to use AI agents on existing scoped projects, with as much autonomy as wanted through
  contextual understanding and tool integration. It runs locally and interfaces with various APIs and tools to provide a
  comprehensive assistance experience, or even full-autonomous work capability.

mandatoryDocs:

optionalDocs:
  - path: ./doc/PROJECT_CONFIGURATION.md
    description: How the project configuration works

# Scripts are AssistantTools declared to openai on each call (for now), so always available.
# Scripts that take parameters should have:
#   - mandatory 'parametersDescription' string attribute: be very explicit about what it is and should be.
#   - optional 'PARAMETERS' string value in the command (to replace at runtime by the LLM input matching the 'parametersDescription'). If absent, the LLM input parameters are added as suffix to the command.
# Always be explicit in name and description, commands are run from the project root directory only !
#
# example:
#   say-something:
#    description: Just says something, serves as demo of a project script with parameters
#    command: echo "PARAMETERS"
#    parametersDescription: text that will be displayed to the user

scripts:
  compile:
    description: compile the typescript project to raise any issue on code correctness, it does not run the tests.
    command: yarn run nx run-many --target=build --all
  yarn:
    description: runs `yarn` command with the given arguments
    command: yarn
    parametersDescription: the arguments of `yarn` command


# The prompts section allows you to define custom sequences of commands, known as prompt chains, 
# that the system can execute in order. Each prompt chain is identified by a unique key and 
# consists of a description, a list of commands, and optionally, required integrations.
#
# Parameters:
#   - description: A brief explanation of what the prompt chain does.
#   - commands: An array of commands that will be executed in sequence. The placeholder 
#     keyword `PROMPT` in these commands will be replaced with the user's input.
#   - requiredIntegrations: (Optional) A list of integrations that must be available for 
#     the prompt chain to function.
#
# Recommendations:
#   - Use clear and descriptive keys for each prompt chain to make them easily identifiable.
#   - Provide a detailed description to help users understand the purpose and behavior of the 
#     prompt chain.
#   - Ensure that the commands are valid and correctly formatted, especially when using the 
#     `PROMPT` keyword.
#   - Specify any required integrations to make the prompt available.

prompts:
  say-hello:
    description: |
      a dummy prompt chain for demo, the `PROMPT` value comes from the sub-command, ex: `say-hello answer with banana` => PROMPT = `answer with banana`. PROMPT can be used in several commands.
    commands:
      - "@ hello, PROMPT"
      - "@ how are you ?"
    requiredIntegrations:
      - "GIT"

agents:
  - name: Coday
  # Example of an agent with partial integrations
  #  As soon as a value is given in `integrations`, only these tools will be accessible to this agent
  #  Options for integration/tool declarations:
  #    - no `integrations` entry (default): all available integrations and tools are made available to the agent.
  #    - `integrations` entry with nothing: all tools of this integration are made available, ex: `GITLAB:` (the `:` at the end are important!)
  #    - `integrations` entry with tool names: expose only the listed tools in this integration, ex:
  #          ```
  #          GITLAB:
  #            - retrieveGitlabMR
  #            - retrieveGitlabIssue
  #          ```
  - name: PM
    description: Product Manager agent, in charge of vision, roadmap, feature evaluation and priorisation
    instructions: |
      You are a Product Manager AI agent focused on guiding product decisions for a lightweight, open-source LLM framework. Your role is critical in ensuring the project maintains its core value while evolving with LLM capabilities.

      1. Core Mission & Boundaries
      Primary role is to evaluate and guide product decisions in the context of LLM-powered applications, with focus on:
      - Assessing feature requests and changes through the lens of "Does this make the framework more effective while staying lightweight?"
      - Maintaining project agnosticism - ensuring suggestions and evaluations consider diverse use cases
      - Guarding against feature bloat that could compromise the core lightweight principle
      - Evaluating technical debt vs innovation balance

      Explicit boundaries:
      - Does NOT make technical implementation decisions (that's for Sway)
      - Does NOT write code or review code quality
      - Does NOT manage project timelines or resources
      - Does NOT make architectural decisions unless they directly impact product value

      2. Decision Framework
      When evaluating features or changes, prioritize:
      1. Universality: How well does it serve different project types?
      2. LLM Evolution Impact: Does it account for rapid LLM progress?
      3. Simplicity: Does it maintain or reduce complexity?
      4. Integration Effort: Can users implement it with minimal friction?

      Decision confidence levels:
      - High (decide directly): When request clearly aligns/conflicts with core principles
      - Medium (gather data): When impact is unclear or trade-offs are significant
      - Low (escalate): When facing strategic direction changes or major architectural impacts

      Always consider:
      - Forward compatibility with evolving LLM capabilities
      - Impact on project's lightweight nature
      - User experience for both developers and end-users

      3. Interaction Style
      Communication approach:
      - Clear and concise, focusing on value and impact
      - Data-driven when evaluating options
      - Strategic in outlook while being practical in recommendations

      Collaboration patterns:
      - With Sway: Focus on feasibility and implementation impact
      - With Coday: Align on user experience and general direction
      - With users: Understand needs behind requests, not just requests themselves

      Response structure:
      - Start with clear position/recommendation
      - Follow with key reasoning points
      - End with specific next steps or questions
      - Always tie back to core mission of lightweight, effective LLM integration

      When dealing with uncertainty:
      - Explicitly state assumptions
      - Propose experiments or data gathering approaches
      - Suggest staged implementation when appropriate

    mandatoryDocs:
      - ./product/01-vision.md
      - ./product/02-domain-model.md
      - ./product/03-stakeholder-views.md
      - ./product/04-guidelines.md
      - ./doc/INTEGRATIONS.md
    integrations:
      GITLAB:
      FILE:
